# Credit Risk Prediction Model

–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Ä–∏—Å–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ –±–∞–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏.

–°–¥–µ–ª–∞–ª –ö—É–ª—ã–≥–∏–Ω –õ–µ–æ–Ω–∏–¥ 

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
account2025/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config/              # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–∏–µ, –¥–∞–Ω–Ω—ã–µ)
‚îÇ   ‚îú‚îÄ‚îÄ data/                # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ model/               # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ (factory, modules, wrapper)
‚îÇ   ‚îú‚îÄ‚îÄ training/            # –û–±—É—á–µ–Ω–∏–µ (trainer, optimizers, schedulers)
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/          # –ú–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∞
‚îÇ   ‚îî‚îÄ‚îÄ utils/               # –£—Ç–∏–ª–∏—Ç—ã (loggers, ClearML, metrics)
‚îú‚îÄ‚îÄ train.py                 # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ inference.py             # –°–∫—Ä–∏–ø—Ç –¥–ª—è inference
‚îú‚îÄ‚îÄ requirements.txt         # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îî‚îÄ‚îÄ README.md               # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

### 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π

```bash
python train.py \
    --config src/config/experiments/baseline.yaml \
    --train-data data/train.csv \
    --val-data data/val.csv
```

### 3. –û–±—É—á–µ–Ω–∏–µ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π (LSTM)

```bash
python train.py \
    --config src/config/experiments/lstm_advanced.yaml \
    --train-data data/train.pq \
    --val-data data/val.pq
```

### 4. Inference –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```bash
python inference.py \
    --model-path outputs/checkpoints/best.pth \
    --data-path data/test.csv \
    --output-path predictions.csv
```

##  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

#### 1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (`model_config.py`)

```python
# RNN —Ç–∏–ø—ã
- GRU (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- LSTM
- RNN

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã RNN
- hidden_size: 64-512 (–æ–±—ã—á–Ω–æ 128-256)
- num_layers: 1-4 (–æ–±—ã—á–Ω–æ 2-3)
- bidirectional: True/False
- dropout: 0.0-0.5

# Entity Embeddings
- use_entity_embedding: True/False
- embedding_formula: "sqrt", "log2", "fixed"

# Dense —Å–ª–æ–∏
- dense_sizes: [512, 256, 64] (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è)
- activation: "relu", "elu", "gelu"
- dropout_rate: 0.0-0.5
```

#### 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è (`training_config.py`)

```python
# –û–ø—Ç–∏–º–∞–π–∑–µ—Ä—ã
- adam
- adamw (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- sgd
- radam

# Scheduler'—ã
- constant
- linear
- cosine (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞)
- cyclical (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è speed)
- exponential
- step

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
- learning_rate: 1e-4 - 1e-2
- batch_size: 32-256
- num_epochs: 20-100
- weight_decay: 1e-6 - 1e-3
```

### –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥–æ–≤

**Baseline (–±—ã—Å—Ç—Ä–æ, —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ):**
```yaml
# src/config/experiments/baseline.yaml
RNN: BiGRU
hidden_size: 128
layers: 2
optimizer: AdamW
scheduler: Cyclical
num_epochs: 50
```

**Advanced LSTM (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ):**
```yaml
# src/config/experiments/lstm_advanced.yaml
RNN: BiLSTM
hidden_size: 256
layers: 3
optimizer: AdamW
scheduler: Cosine
num_epochs: 100
```

**Lightweight (–±—ã—Å—Ç—Ä–æ, –¥–ª—è –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è):**
```python
from src.model.factory import PresetConfigs
model = PresetConfigs.get_lightweight()
```

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏

### Flow –¥–∞–Ω–Ω—ã—Ö

```
–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    ‚Üì
[Word2Vec + TF-IDF] ‚Üí –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ–ø–∏—Å–∞–Ω–∏–π (50 dim)
    ‚Üì
[Entity Embeddings] ‚Üí –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    ‚Üì
[BiGRU/BiLSTM] ‚Üí RNN –æ–±—Ä–∞–±–æ—Ç–∫–∞ (128-256 hidden)
    ‚Üì
[Max/Avg Pooling] ‚Üí –ò—Å—Ç–æ—Ä–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥
    ‚Üì
–ü—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    ‚Üì
[Dense layers] ‚Üí –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (512‚Üí256‚Üí64‚Üí1)
    ‚Üì
[Sigmoid] ‚Üí –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ñ–æ–ª—Ç–∞
```

### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

1. **EmbeddingLayer** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π
2. **EntityEmbedding** - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
3. **RNNEncoder** - BiGRU/BiLSTM –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
4. **DenseClassifier** - —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

##  –ú–µ—Ç—Ä–∏–∫–∏

### –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏

- **Gini** - –º–µ—Ç—Ä–∏–∫–∞ –î–∂–∏–Ω–∏ (–æ—Å–Ω–æ–≤–Ω–∞—è –¥–ª—è –±–∞–Ω–∫–æ–≤)
- **ROC-AUC** - –∫—Ä–∏–≤–∞—è –ø–æ–¥ ROC
- **Precision / Recall** - —Ç–æ—á–Ω–æ—Å—Ç—å –∏ –ø–æ–ª–Ω–æ—Ç–∞
- **F1-Score** - –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
- **KS-Statistic** - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Å ClearML

```python
from src.utils.clearml_utils import ClearMLLogger

logger = ClearMLLogger(
    project_name="credit-risk",
    task_name="baseline-experiment"
)

# –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥
logger.log_config(config_dict)

# –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
logger.log_metrics({"train/loss": 0.45, "val/gini": 55.2}, step=epoch)

# –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å
logger.log_model(model_path, "best_model")
```

##  Factory –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ

### –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Factory

```python
from src.config.model_config import ModelConfig
from src.model.factory import ModelFactory

# –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥
config = ModelConfig(
    rnn.hidden_size=256,
    rnn.num_layers=3,
    rnn.rnn_type="LSTM",
    rnn.bidirectional=True,
)

# –°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å
model = ModelFactory.create(config)
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–æ–∫

```python
from src.model.factory import PresetConfigs

# –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
model = PresetConfigs.get_baseline()

# LSTM advanced
model = PresetConfigs.get_lstm_advanced()

# Lightweight
model = PresetConfigs.get_lightweight()

# BiGRU —Å –≤–Ω–∏–º–∞–Ω–∏–µ–º
model = PresetConfigs.get_bidgru_with_attention()
```

##  –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –∏ Scheduler'—ã

### Factory –¥–ª—è –æ–ø—Ç–∏–º–∞–π–∑–µ—Ä–æ–≤

```python
from src.training.optimizer_factory import create_optimizer
from src.config.training_config import OptimizerConfig

config = OptimizerConfig(
    optimizer_type="adamw",
    learning_rate=1e-3,
    weight_decay=1e-4,
)

optimizer = create_optimizer(model.parameters(), config)
```

### Factory –¥–ª—è scheduler'–æ–≤

```python
from src.training.scheduler_factory import create_scheduler
from src.config.training_config import SchedulerConfig

config = SchedulerConfig(
    scheduler_type="cyclical",
    base_lr=1e-3,
    max_lr=1e-2,
    cycle_size=4,
)

scheduler = create_scheduler(optimizer, config, num_epochs=50)
```

### Cyclical Learning Rate

–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –≤—ã—Ö–æ–¥–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤:

```yaml
scheduler:
  scheduler_type: "cyclical"
  base_lr: 0.001       # –ù–∏–∑–∫–∏–π LR
  max_lr: 0.01         # –í—ã—Å–æ–∫–∏–π LR
  cycle_size: 4        # –¶–∏–∫–ª –∫–∞–∂–¥—ã–µ 4 —ç–ø–æ—Ö–∏
```

### Cosine Annealing

–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞:

```yaml
scheduler:
  scheduler_type: "cosine"
  t_max: 100           # –ú–∞–∫—Å–∏–º—É–º —ç–ø–æ—Ö
  eta_min: 0.000001    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π LR
```

##  –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ü–æ–∏—Å–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

```bash
python hyperparameter_search.py \
    --train-data data/train.csv \
    --val-data data/val.csv \
    --search-type grid  # –∏–ª–∏ random
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥–æ–≤

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥–æ–≤ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
python train.py --config src/config/experiments/baseline.yaml
python train.py --config src/config/experiments/lstm_advanced.yaml

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤ ClearML Dashboard
```

##  –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –û–±—É—á–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π

```python
from src.config.model_config import ModelConfig
from src.config.training_config import TrainingConfig
from src.model.factory import ModelFactory
from train import TrainingPipeline

# –ö–æ–Ω—Ñ–∏–≥–∏
model_config = ModelConfig.get_baseline()
training_config = TrainingConfig.get_baseline()

# –ü–∞–π–ø–ª–∞–π–Ω
pipeline = TrainingPipeline(model_config, training_config)
pipeline.train(train_loader, val_loader)
```

### –ü—Ä–∏–º–µ—Ä 2: –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```python
from src.config.model_config import (
    ModelConfig, RNNConfig, RNNType, DenseConfig
)
from src.config.training_config import (
    TrainingConfig, OptimizerConfig, SchedulerConfig,
    OptimizerType, SchedulerType
)

# –ö–∞—Å—Ç–æ–º–Ω–∞—è RNN –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
rnn_config = RNNConfig(
    rnn_type=RNNType.LSTM,
    hidden_size=512,
    num_layers=4,
    bidirectional=True,
    dropout=0.4,
)

# –ö–∞—Å—Ç–æ–º–Ω–∞—è Dense –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
dense_config = DenseConfig(
    dense_sizes=[1024, 512, 256, 128],
    dropout_rate=0.3,
    activation="gelu",
)

# –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ ModelConfig
model_config = ModelConfig(
    rnn=rnn_config,
    dense=dense_config,
    dropout_spatial=0.3,
)

# –ö–∞—Å—Ç–æ–º–Ω–∞—è training –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
training_config = TrainingConfig(
    optimizer=OptimizerConfig(
        optimizer_type=OptimizerType.ADAMW,
        learning_rate=5e-4,
        weight_decay=1e-5,
    ),
    scheduler=SchedulerConfig(
        scheduler_type=SchedulerType.COSINE,
        t_max=200,
    ),
    num_epochs=150,
    batch_size=32,
)
```

### –ü—Ä–∏–º–µ—Ä 3: Inference

```python
from inference import CreditRiskInference
from src.config.model_config import ModelConfig

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
model_config = ModelConfig.get_baseline()
inference = CreditRiskInference(
    model_path="outputs/checkpoints/best.pth",
    model_config=model_config,
    device="cuda"
)

# –°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
predictions = inference.predict(
    transaction_sequences=batch_trans,
    categorical_features=batch_cat,
    offer_features=batch_offer,
)
```

##  –û—Ç–ª–∞–¥–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑

### –í–∫–ª—é—á–∏—Ç—å debug —Ä–µ–∂–∏–º

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏

```python
from src.model.factory import ModelFactory
from src.config.model_config import ModelConfig

config = ModelConfig.get_baseline()
model = ModelFactory.create(config)
print(model)

# –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Total params: {total_params:,}")
print(f"Trainable params: {trainable_params:,}")
```

### –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫

```python
from src.utils.clearml_utils import MetricsLogger

metrics_logger = MetricsLogger()
history = metrics_logger.get_history()


metrics_logger.save()
```

## Best Practices

1. **–ù–∞—á–Ω–∏—Ç–µ —Å baseline** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `ModelConfig.get_baseline()` –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∞
2. **Cyclical LR –¥–ª—è speed** - `SchedulerType.CYCLICAL` –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
3. **Cosine –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞** - `SchedulerType.COSINE` –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
4. **AdamW –≤–º–µ—Å—Ç–æ Adam** - –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
5. **–õ–æ–≥–∏—Ä—É–π—Ç–µ –≤ ClearML** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –≤—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
6. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ early stopping** - –∏–∑–±–µ–∂–∏—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
7. **–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ checkpoints** - –ª—É—á—à—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å
